import json
import subprocess
import argparse
import os
import sys
from jinja2 import Template

def format_size(size_bytes):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ø¨Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ù†Ø§Ø³Ø¨Ø©"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"

def get_image_size_from_docker_manifest(image_tag, arch):
    """
    Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù€ image Ù…Ù† Docker manifest Ù…Ø¨Ø§Ø´Ø±Ø©
    """
    try:
        # ØªØ´ØºÙŠÙ„ docker manifest inspect
        cmd = f"docker manifest inspect --verbose {image_tag}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, check=False)
        
        if result.returncode != 0:
            print(f"âš ï¸  Warning: Failed to inspect {image_tag}: {result.stderr}", file=sys.stderr)
            return "N/A", "N/A"
        
        # Parse JSON
        manifests = json.loads(result.stdout)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù€ manifest Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        for manifest in manifests:
            descriptor = manifest.get("Descriptor", {})
            platform = descriptor.get("platform", {})
            
            if platform.get("architecture") == arch and platform.get("os") == "linux":
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ OCIManifest
                oci_manifest = manifest.get("OCIManifest", {})
                if not oci_manifest:
                    continue
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù…
                total_size = 0
                
                # Ø¥Ø¶Ø§ÙØ© Ø­Ø¬Ù… Ø§Ù„Ù€ layers
                layers = oci_manifest.get("layers", [])
                for layer in layers:
                    total_size += layer.get("size", 0)
                
                # Ø¥Ø¶Ø§ÙØ© Ø­Ø¬Ù… Ø§Ù„Ù€ config
                config = oci_manifest.get("config", {})
                total_size += config.get("size", 0)
                
                # Ø§Ù„Ù€ digest
                digest = descriptor.get("digest", "")
                
                return format_size(total_size), digest
        
        print(f"âš ï¸  Warning: No manifest found for {arch} in {image_tag}", file=sys.stderr)
        return "N/A", "N/A"
        
    except Exception as e:
        print(f"âŒ Error getting image size for {image_tag}/{arch}: {e}", file=sys.stderr)
        return "N/A", "N/A"

def extract_artifact_links(metadata, target_key, image_tag, run_id=None):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù€ artifacts (SBOM, provenance, attestations) Ù…Ù† metadata
    """
    artifacts = {
        'sbom': None,
        'provenance': None,
        'attestation': None,
        'cosign_sbom': None,
        'cosign_provenance': None
    }
    
    if target_key not in metadata:
        return artifacts
    
    target_metadata = metadata[target_key]
    image_name = image_tag.split(':')[0] if image_tag else None
    digest = target_metadata.get('containerimage.digest', '')
    
    if not image_name or not digest:
        return artifacts
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ org Ùˆ repo Ù…Ù† image name
    # Ù…Ø«Ø§Ù„: ghcr.io/taha2samy/java -> owner=taha2samy, repo=java
    if 'ghcr.io' in image_name:
        parts = image_name.replace('ghcr.io/', '').split('/')
        if len(parts) >= 2:
            owner = parts[0]
            repo = parts[1]
            
            # GitHub Attestations API URLs
            # https://github.com/{owner}/{package}/attestations/{digest}
            base_attestation_url = f"https://github.com/{owner}/{repo}/attestations"
            
            # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù€ attestations Ø¹Ù„Ù‰ GitHub
            artifacts['sbom'] = f"{base_attestation_url}/{digest.replace('sha256:', '')}"
            artifacts['provenance'] = f"{base_attestation_url}/{digest.replace('sha256:', '')}"
            artifacts['attestation'] = f"{base_attestation_url}/{digest.replace('sha256:', '')}"
            
            # Ø±ÙˆØ§Ø¨Ø· Cosign Ù„Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            artifacts['cosign_sbom'] = f"{image_name}@{digest}"
            artifacts['cosign_provenance'] = f"{image_name}@{digest}"
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† ÙÙŠ run_idØŒ Ù†Ø¶ÙŠÙ Ø±Ø§Ø¨Ø· Ø§Ù„Ù€ GitHub Actions artifacts
    if run_id:
        artifacts['github_actions'] = f"https://github.com/{owner}/{repo}/actions/runs/{run_id}"
    
    return artifacts

def main():
    parser = argparse.ArgumentParser(description='Generate README from Docker images')
    parser.add_argument('--metadata', required=True, help='Path to metadata JSON file')
    parser.add_argument('--template', required=True, help='Path to Jinja2 template file')
    parser.add_argument('--version', required=True, help='Java version (e.g., 11, 17, 21)')
    parser.add_argument('--output', required=True, help='Output path for generated README')
    args_cli = parser.parse_args()

    # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù€ metadata
    try:
        with open(args_cli.metadata, 'r') as f:
            metadata = json.load(f)
    except FileNotFoundError:
        print(f"âŒ Error: Metadata file not found: {args_cli.metadata}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"âŒ Error: Invalid JSON in metadata file: {e}", file=sys.stderr)
        sys.exit(1)

    v = args_cli.version
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù€ targets
    targets = {
        'jdk': f"java{v}-jdk-std",
        'jre': f"java{v}-jre-std",
        'dist': f"java{v}-jre-distroless"
    }

    def get_image_tags(target_key):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ tags Ù…Ù† metadata (GHCR Ùˆ DockerHub)"""
        if target_key not in metadata:
            return {'ghcr': None, 'dockerhub': None}
        
        image_names = metadata[target_key].get("image.name", "")
        names = [name.strip() for name in image_names.split(',')]
        
        ghcr = next((n for n in names if 'ghcr.io' in n), None)
        dockerhub = next((n for n in names if 'ghcr.io' not in n and n), None)
        
        return {'ghcr': ghcr, 'dockerhub': dockerhub}

    # Ø¬Ù„Ø¨ tags
    image_tags = {k: get_image_tags(tk) for k, tk in targets.items()}

    # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª provenance
    try:
        prov = metadata[targets['jdk']]["buildx.build.provenance/linux/amd64"]
        build_args = prov["invocation"]["parameters"]["args"]
        builder_id = prov["builder"]["id"]
        run_id = builder_id.split('/')[-3] if '/' in builder_id else None
    except KeyError as e:
        print(f"âŒ Error: Missing key in metadata: {e}", file=sys.stderr)
        sys.exit(1)

    print("ğŸ” Fetching image details from manifests...")
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø­Ø¬Ø§Ù… ÙˆØ§Ù„Ù€ digests Ù„ÙƒÙ„ variant ÙˆÙƒÙ„ architecture
    variants = {}
    for variant_key, variant_name in [('jdk', 'JDK Standard'), 
                                       ('jre', 'JRE Standard'), 
                                       ('dist', 'JRE Distroless')]:
        
        ghcr_tag = image_tags[variant_key]['ghcr']
        dockerhub_tag = image_tags[variant_key]['dockerhub']
        
        # Ù†Ø³ØªØ®Ø¯Ù… GHCR ÙƒÙ€ primary source
        primary_tag = ghcr_tag or dockerhub_tag
        
        if primary_tag:
            print(f"  ğŸ“¦ Processing {variant_name}...")
            amd_size, amd_digest = get_image_size_from_docker_manifest(primary_tag, "amd64")
            arm_size, arm_digest = get_image_size_from_docker_manifest(primary_tag, "arm64")
            
            # Ø¬Ù„Ø¨ artifact links
            artifacts = extract_artifact_links(metadata, targets[variant_key], primary_tag, run_id)
            
            variants[variant_key] = {
                'amd64': {'size': amd_size, 'digest': amd_digest},
                'arm64': {'size': arm_size, 'digest': arm_digest},
                'ghcr_tag': ghcr_tag,
                'dockerhub_tag': dockerhub_tag,
                'artifacts': artifacts
            }
        else:
            print(f"  âš ï¸  Warning: No tags found for {variant_name}")
            variants[variant_key] = {
                'amd64': {'size': 'N/A', 'digest': 'N/A'},
                'arm64': {'size': 'N/A', 'digest': 'N/A'},
                'ghcr_tag': None,
                'dockerhub_tag': None,
                'artifacts': {'sbom': None, 'provenance': None, 'attestation': None}
            }

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ full SHA references
    def build_full_sha(tag, digest):
        if not tag or digest == "N/A":
            return "N/A"
        image_name = tag.split(':')[0]
        return f"`{image_name}@{digest}`"

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ context Ù„Ù„Ù€ template
    context = {
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø©
        "full_version": build_args.get("build-arg:JAVA_FULL_VERSION", "N/A"),
        "Version": build_args.get("build-arg:JAVA_VER", v),
        "build_date": build_args.get("build-arg:JAVA_UPSTREAM_UPDATE", "").split('T')[0],
        "upstream_date": build_args.get("build-arg:JAVA_UPSTREAM_UPDATE", "").split('T')[0],
        "build_proof": builder_id,
        "sbom": f"https://github.com/taha2samy/openjdk/actions/runs/{run_id}" if run_id else "N/A",
        "docker_pulls": "https://img.shields.io/docker/pulls/taha2samy/java?style=flat&logo=docker",
        "docker_pulls_url": "https://hub.docker.com/r/taha2samy/java",
        "vulnerability_scan_badge": "https://github.com/taha2samy/openjdk/actions/workflows/build-images.yml/badge.svg",
        
        # JDK Standard
        "amd64_jdk_size": variants['jdk']['amd64']['size'],
        "arm64_jdk_size": variants['jdk']['arm64']['size'],
        "amd64_jdk_full_sha": build_full_sha(variants['jdk']['ghcr_tag'], variants['jdk']['amd64']['digest']),
        "arm64_jdk_full_sha": build_full_sha(variants['jdk']['ghcr_tag'], variants['jdk']['arm64']['digest']),
        "amd64_jdk_digest": f"`{metadata[targets['jdk']].get('containerimage.digest', 'N/A')}`",
        "jdk_sbom_url": variants['jdk']['artifacts']['sbom'] if variants['jdk']['artifacts']['sbom'] else "N/A",
        "jdk_provenance_url": variants['jdk']['artifacts']['provenance'] if variants['jdk']['artifacts']['provenance'] else "N/A",
        "jdk_attestation_url": variants['jdk']['artifacts']['attestation'] if variants['jdk']['artifacts']['attestation'] else "N/A",
        "jdk_cosign_sbom": variants['jdk']['artifacts']['cosign_sbom'] if variants['jdk']['artifacts']['cosign_sbom'] else "N/A",
        
        # JRE Standard
        "amd64_jre_size": variants['jre']['amd64']['size'],
        "arm64_jre_size": variants['jre']['arm64']['size'],
        "amd64_jre_full_sha": build_full_sha(variants['jre']['ghcr_tag'], variants['jre']['amd64']['digest']),
        "arm64_jre_full_sha": build_full_sha(variants['jre']['ghcr_tag'], variants['jre']['arm64']['digest']),
        "amd64_jre_digest": f"`{metadata[targets['jre']].get('containerimage.digest', 'N/A')}`",
        "jre_sbom_url": variants['jre']['artifacts']['sbom'] if variants['jre']['artifacts']['sbom'] else "N/A",
        "jre_provenance_url": variants['jre']['artifacts']['provenance'] if variants['jre']['artifacts']['provenance'] else "N/A",
        "jre_attestation_url": variants['jre']['artifacts']['attestation'] if variants['jre']['artifacts']['attestation'] else "N/A",
        "jre_cosign_sbom": variants['jre']['artifacts']['cosign_sbom'] if variants['jre']['artifacts']['cosign_sbom'] else "N/A",
        
        # JRE Distroless
        "amd64_distroless_size": variants['dist']['amd64']['size'],
        "arm64_distroless_size": variants['dist']['arm64']['size'],
        "amd64_dist_full_sha": build_full_sha(variants['dist']['ghcr_tag'], variants['dist']['amd64']['digest']),
        "arm64_dist_full_sha": build_full_sha(variants['dist']['ghcr_tag'], variants['dist']['arm64']['digest']),
        "amd64_distroless_digest": f"`{metadata[targets['dist']].get('containerimage.digest', 'N/A')}`",
        "dist_sbom_url": variants['dist']['artifacts']['sbom'] if variants['dist']['artifacts']['sbom'] else "N/A",
        "dist_provenance_url": variants['dist']['artifacts']['provenance'] if variants['dist']['artifacts']['provenance'] else "N/A",
        "dist_attestation_url": variants['dist']['artifacts']['attestation'] if variants['dist']['artifacts']['attestation'] else "N/A",
        "dist_cosign_sbom": variants['dist']['artifacts']['cosign_sbom'] if variants['dist']['artifacts']['cosign_sbom'] else "N/A",
        
        # Legacy naming (backward compatibility)
        "amd64_jdk_sbom": f"https://{variants['jdk']['ghcr_tag']}" if variants['jdk']['ghcr_tag'] else "N/A",
        "amd64_jre_sbom": f"https://{variants['jre']['ghcr_tag']}" if variants['jre']['ghcr_tag'] else "N/A",
        "amd64_distroless_sbom": f"https://{variants['dist']['ghcr_tag']}" if variants['dist']['ghcr_tag'] else "N/A",
    }

    # Ù‚Ø±Ø§Ø¡Ø© ÙˆØªÙ†ÙÙŠØ° Ø§Ù„Ù€ template
    try:
        with open(args_cli.template, 'r', encoding='utf-8') as f:
            template_content = f.read()
        
        tpl = Template(template_content)
        rendered = tpl.render(context)
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù†Ø§ØªØ¬
        output_dir = os.path.dirname(args_cli.output)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        with open(args_cli.output, 'w', encoding='utf-8') as f:
            f.write(rendered)
        
        print(f"\nâœ… README generated successfully: {args_cli.output}")
        
    except FileNotFoundError:
        print(f"âŒ Error: Template file not found: {args_cli.template}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Error: Failed to generate README: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()